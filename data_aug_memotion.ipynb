{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6c4d7d",
   "metadata": {},
   "source": [
    "# process memotion dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e9f73",
   "metadata": {},
   "source": [
    "### 1. remove crashed images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1907f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "home = '/home/chen_zhang06/HatefulMemes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4d8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(memo):\n",
    "    import re\n",
    "    from collections import Counter\n",
    "\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text_to_remove = [\"imgflip.com\", \"imgflip\", \"quickmeme.com\", \"quickmeme\",\n",
    "                      \"memecenter.com\", \"memecenter\", \"memegenerator.net\",\n",
    "                      \"memegenerator\", \"9gag.com\", \"arhtisticlicense.com\",\n",
    "                      \"starecat.com\", \"gapbagap.net\", \"dudelol.com\"]\n",
    "\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(text_to_remove))\n",
    "\n",
    "    memo.text = memo.text.str.lower()\n",
    "    # Remove URLs\n",
    "    memo.text = memo.text.str.replace(url_pattern, \"\")\n",
    "    # Remove words in 'text_to_remove'\n",
    "    memo.text = memo.text.str.replace(pat, '')\n",
    "    # Remove any character that's not a letter or a number\n",
    "    memo.text = memo.text.replace(r\"[\\W_]+\", \" \", regex=True)\n",
    "    memo = memo.dropna()\n",
    "    return memo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "773c01fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6992 rows and 9 columns: \n",
      " ['Unnamed: 0', 'image_name', 'text_ocr', 'text_corrected', 'humour', 'sarcasm', 'offensive', 'motivational', 'overall_sentiment']\n",
      "\n",
      "-------------- ['not_offensive' 'very_offensive' 'slight' 'hateful_offensive']\n",
      "# of 'not_offensive' memes \t: 2713\n",
      "# of 'very_offensive' memes \t: 1466\n",
      "# of 'slight' memes \t: 2592\n",
      "# of 'hateful_offensive' memes \t: 221\n",
      "                  id                                               text  \\\n",
      "0        image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
      "1       image_2.jpeg  The best of #10 YearChallenge! Completed in le...   \n",
      "2        image_3.JPG  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
      "3        image_4.png              10 Year Challenge - Sweet Dee Edition   \n",
      "4        image_5.png  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
      "...              ...                                                ...   \n",
      "6987  image_6988.jpg  Tuesday is Mardi Gras Wednesday is Valentine's...   \n",
      "6988  image_6989.jpg  MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...   \n",
      "6989  image_6990.png  LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...   \n",
      "6990  image_6991.jpg  When I have time is a fantasy. no one has time...   \n",
      "6991  image_6992.jpg  The starting point for every good idea is \"Wha...   \n",
      "\n",
      "               label  \n",
      "0      not_offensive  \n",
      "1      not_offensive  \n",
      "2      not_offensive  \n",
      "3     very_offensive  \n",
      "4     very_offensive  \n",
      "...              ...  \n",
      "6987  very_offensive  \n",
      "6988   not_offensive  \n",
      "6989          slight  \n",
      "6990   not_offensive  \n",
      "6991   not_offensive  \n",
      "\n",
      "[6992 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# getting csv and image data\n",
    "path2img = os.path.join(home, \"memotion_dataset_7k/images/\")\n",
    "path2data = os.path.join(home, \"memotion_dataset_7k/labels.csv\")\n",
    "df = pd.read_csv(path2data, delimiter=',')\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns: \\n {list(df.columns)}\\n')\n",
    "print('--------------', df[\"offensive\"].unique())\n",
    "# print(df.head)\n",
    "\n",
    "for i in df[\"offensive\"].unique():\n",
    "    print(f\"# of '{i}' memes \\t: {len(df[df['offensive']==i])}\")\n",
    "\n",
    "columns = [\"image_name\", \"text_corrected\", 'offensive']\n",
    "# hateful_offensive = df[df[\"offensive\"]==\"hateful_offensive\"][columns]\n",
    "hateful_offensive = df[df[\"offensive\"].isin(df[\"offensive\"].unique())][columns]\n",
    "# print(hateful_offensive)\n",
    "# very_offensive    = df[df[\"offensive\"]==\"very_offensive\"][columns]\n",
    "# not_offensive          = df[df[\"offensive\"]==\"not_offensive\"][columns]\n",
    "\n",
    "memo = df[columns]\n",
    "memo.columns = [\"id\", \"text\", 'label']\n",
    "print(memo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efcc41d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:793: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n"
     ]
    }
   ],
   "source": [
    "# locate empty or mismatched files: \n",
    "img_dir = os.path.join(home, 'memotion_dataset_7k/images/')\n",
    "emptyfile = []\n",
    "for i in memo['id']: \n",
    "    try: \n",
    "        path = os.path.join(img_dir, i)\n",
    "        img = Image.open(path)\n",
    "        im = np.array(img).astype(np.float32)\n",
    "    except: \n",
    "        emptyfile.append(i)\n",
    "print(len(emptyfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "010f52e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4155, 3)\n",
      "(4155, 3)\n"
     ]
    }
   ],
   "source": [
    "# remove those lines in the pd file, and remove the 'slight' offensive category, as it might be confusing\n",
    "print(memo.shape)\n",
    "memo.drop(memo[memo['id'].isin(emptyfile)].index, inplace = True)\n",
    "memo.drop(memo[memo['label'] == 'slight'].index, inplace = True)\n",
    "print(memo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd76c15",
   "metadata": {},
   "source": [
    "### 2. Re-assign label values, move those images to another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d210686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then re-assign the label value: \n",
    "hatefullist = ['hateful_offensive', 'very_offensive']\n",
    "# nonhatefullist = ['not_offensive', 'slight', 'very_offensive']\n",
    "nonhatefullist = ['not_offensive']\n",
    "memo.loc[memo['label'].isin(hatefullist), 'label'] = 1\n",
    "memo.loc[memo['label'].isin(nonhatefullist), 'label'] = 0\n",
    "\n",
    "# Add missing columns so it looks like Hateful Memes data\n",
    "memo[\"img\"] = (\"img/\" + memo[\"id\"])\n",
    "memo[\"img\"] = memo[\"img\"].str.lower()\n",
    "# remove extension in \"image_name\" & get the number of the image & add 100k, cause the HM data ID's goes up to 99k\n",
    "memo[\"id\"] = memo[\"id\"].str.split(\".\").str.get(0).str.split(\"_\").str.get(1).astype(int) + 100_000\n",
    "# Re-order columns\n",
    "memo = memo[[\"id\", \"img\", 'label', \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12037f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img label  \\\n",
      "0     100001     img/image_1.jpg     0   \n",
      "1     100002    img/image_2.jpeg     0   \n",
      "2     100003     img/image_3.jpg     0   \n",
      "3     100004     img/image_4.png     1   \n",
      "4     100005     img/image_5.png     1   \n",
      "...      ...                 ...   ...   \n",
      "6986  106987  img/image_6987.jpg     0   \n",
      "6987  106988  img/image_6988.jpg     1   \n",
      "6988  106989  img/image_6989.jpg     0   \n",
      "6990  106991  img/image_6991.jpg     0   \n",
      "6991  106992  img/image_6992.jpg     0   \n",
      "\n",
      "                                                   text  \n",
      "0     look there my friend lightyear now all sohalik...  \n",
      "1     the best of 10 yearchallenge completed in less...  \n",
      "2     sam thorne strippin follow follow saw everyone...  \n",
      "3                   10 year challenge sweet dee edition  \n",
      "4     10 year challenge with no filter 47 hilarious ...  \n",
      "...                                                 ...  \n",
      "6986  if you re going on and on and on about your pr...  \n",
      "6987  tuesday is mardi gras wednesday is valentine s...  \n",
      "6988  must watch movies of 2017 iti chennai memes ma...  \n",
      "6990  when i have time is a fantasy no one has time ...  \n",
      "6991  the starting point for every good idea is what...  \n",
      "\n",
      "[4151 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "# Pre-process the text in memes\n",
    "memo = preprocess_text(memo)\n",
    "print(memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7cbfa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy these files into another folder: memotion_dataset_7k/images_selected/\n",
    "import zipfile\n",
    "flist = list(memo['img'].str.split('/').str.get(1))\n",
    "# print(flist)\n",
    "\n",
    "import os\n",
    "os.chdir(os.path.join(home, 'memotion_dataset_7k/images/'))\n",
    "with zipfile.ZipFile('memotion_selected.zip', 'w') as zipMe:        \n",
    "    for file in flist:\n",
    "        try: \n",
    "            zipMe.write(file, compress_type=zipfile.ZIP_DEFLATED)\n",
    "        except: pass\n",
    "!mv memotion_selected.zip ../images_selected/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec7f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(home, 'memotion_dataset_7k/images_selected/'))\n",
    "!unzip memotion_selected.zip\n",
    "# !rm -rf memotion_selected.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d61ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf memotion_selected.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0baab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4138\n"
     ]
    }
   ],
   "source": [
    "# check number of images: 4138\n",
    "!ls -F | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70607891",
   "metadata": {},
   "source": [
    "### 3. generate jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "608cc754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img label  \\\n",
      "0     100001     img/image_1.jpg     0   \n",
      "1     100002    img/image_2.jpeg     0   \n",
      "2     100003     img/image_3.jpg     0   \n",
      "3     100004     img/image_4.png     1   \n",
      "4     100005     img/image_5.png     1   \n",
      "...      ...                 ...   ...   \n",
      "6986  106987  img/image_6987.jpg     0   \n",
      "6987  106988  img/image_6988.jpg     1   \n",
      "6988  106989  img/image_6989.jpg     0   \n",
      "6990  106991  img/image_6991.jpg     0   \n",
      "6991  106992  img/image_6992.jpg     0   \n",
      "\n",
      "                                                   text  \n",
      "0     look there my friend lightyear now all sohalik...  \n",
      "1     the best of 10 yearchallenge completed in less...  \n",
      "2     sam thorne strippin follow follow saw everyone...  \n",
      "3                   10 year challenge sweet dee edition  \n",
      "4     10 year challenge with no filter 47 hilarious ...  \n",
      "...                                                 ...  \n",
      "6986  if you re going on and on and on about your pr...  \n",
      "6987  tuesday is mardi gras wednesday is valentine s...  \n",
      "6988  must watch movies of 2017 iti chennai memes ma...  \n",
      "6990  when i have time is a fantasy no one has time ...  \n",
      "6991  the starting point for every good idea is what...  \n",
      "\n",
      "[4151 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "043326e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = memo.to_json(orient='records', lines=True)\n",
    "with open(os.path.join(home, \"annotations/label_memotion.jsonl\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620ea29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
