{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnbmxkjqXDNy"
   },
   "source": [
    "# <font color='Aqua'> <b> Team HateDetectron - Phase-2 Submissions </b> </font>\n",
    "\n",
    "---\n",
    "This notebook is only for reproducing the results of Phase-2 submissions by the team `HateDetectron`. In other words, just loading the final models and getting predictions for the test set. See the [end2end-process notebook](https://colab.research.google.com/drive/1O0m0j9_NBInzdo3K04jD19IyOhBR1I8i?usp=sharing) to see the whole approach in detail: how the models are trained, how the image features are extracted, which datasets are used, etc.\n",
    "\n",
    "---\n",
    "**Author:**\\\n",
    "<font color='Wheat'>\n",
    "    <b>\n",
    "        Riza Velioglu\n",
    "    </b>\n",
    "</font>\n",
    "\n",
    "**Contact:**\n",
    "\n",
    "<center>\n",
    "<a href=\"http://rizavelioglu.github.io/\"><img src=\"https://drive.google.com/uc?id=1SWc-ryZf7xxZ_g7AdU_vn2Y451IcCisw\" width=\"300\"></a>\n",
    "\n",
    "[Webpage](http://rizavelioglu.github.io/)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "pruHlZCZht3p"
   },
   "outputs": [],
   "source": [
    "#@markdown ---\n",
    "#@title <h1><b> <font color='lightblue'> Running the whole notebook at once! </font> <font color='red'> --Action required!-- </b></font></h1> { run: \"auto\" }\n",
    "#@markdown First, please specify the download link and the `.zip` password which both can be taken from [DrivenData](https://www.drivendata.org/competitions/70/hateful-memes-phase-2/data/)\n",
    "\n",
    "\n",
    "YOUR_LINK_TO_DOWNLOAD_PHASE2_DATA = '' #@param {type:\"string\"}\n",
    "PASSWORD_OF_ZIP = '' #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Then run all the cells:\n",
    "#@markdown - <font color='yellow'> Colab </font>: **\"Runtime\" > \"Run All\"** *OR* `Ctrl+F9`\n",
    "#@markdown - <font color='orange'> Jupyter Notebook </font>: **\"Cell\" > \"Run All\"**\n",
    "#@markdown ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-oZg0MPdTPu"
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "<details><summary>\n",
    "<font color='Tan'> I. Installation of MMF & dependencies </font></summary>\n",
    "\n",
    "- install MMF dependencies\n",
    "- install MMF from source\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "<font color='Tan'> II. Download the dataset & convert it into MMF format </font></summary>\n",
    "\n",
    "- download Hateful Memes (HM) dataset\n",
    "- convert HM into MMF format (unzip and place the dataset to a specific location)\n",
    "- remove unnecessary data to keep the disk clean\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>\n",
    "<font color='Tan'> III. Feature Extraction </font></summary>\n",
    "\n",
    "- download image features (.zip files) for 2 datasets:  HM and [Memotion](https://www.kaggle.com/williamscott701/memotion-dataset-7k) [( see paper )](https://arxiv.org/pdf/2008.03781.pdf)\n",
    "- extract the two `.zip` files and merge them into one folder\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "<font color='Tan'> IV. Validating'fine-tuned' VisualBERT models on `dev_unseen.jsonl` </font></summary>\n",
    "\n",
    "- download fine-tuned models that were used in Phase-2 submission\n",
    "- evaluate them on 'dev_unseen' data\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>\n",
    "<font color='Tan'> V. Generate predictions for the Challenge (`test_unseen.jsonl`) </font></summary>\n",
    "\n",
    "- generate predictions for 2 submissions in Phase-2\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kE9_rJZfF_Rf"
   },
   "source": [
    "## <font color='magenta'> <b> I. Installation of MMF & dependencies </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7V112rAEiK9"
   },
   "source": [
    "Please set your `$HOME` directory.\\\n",
    "**e.g.** For <font color='orange'> Linux </font> users it can be: `\"/home/project_folder\"`,\\\n",
    "For <font color='yellow'> Colab </font> it would be: `\"/content\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ATqmsZVmEhXc",
    "outputId": "191a064f-3281-4f3a-df00-1837b0de3e5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\OMSCS\\\\DL\\\\project\\\\HatefulMemes'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "home = \"./\"\n",
    "os.chdir(home)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JeJ7JdvoKPB",
    "outputId": "f2c95337-f86a-49a7-d3d8-d38d22461437"
   },
   "outputs": [],
   "source": [
    "# Install specified versions of `torch` and `torchvision`, before installing mmf (causes an issue)\n",
    "# !pip install torch==1.6.0 torchvision==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rna7NAZtwaod"
   },
   "source": [
    "#### *Install MMF from source* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtyIgblgvdoY",
    "outputId": "cf3da981-7fe7-4440-cc51-5988882624ae"
   },
   "outputs": [],
   "source": [
    "# Clone the following repo where mmf does not install default image features, \n",
    "# since we will use our own features\n",
    "!git clone --branch no_feats --config core.symlinks=true https://github.com/rizavelioglu/mmf.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oHzXv9ogv3K8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(home, \"mmf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eVZPra-wMgt",
    "outputId": "b3c539da-60dc-47ee-cfae-512b84d2c29e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///F:/OMSCS/DL/project/HatefulMemes/mmf\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: transformers==3.4.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (3.4.0)\n",
      "Requirement already satisfied: termcolor==1.1.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (1.1.0)\n",
      "Requirement already satisfied: torchvision==0.7.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (0.7.0+cu101)\n",
      "Requirement already satisfied: torchtext==0.5.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (0.5.0)\n",
      "Requirement already satisfied: GitPython==3.1.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (3.1.0)\n",
      "Collecting editdistance==0.5.3\n",
      "  Using cached editdistance-0.5.3-cp36-cp36m-win_amd64.whl (23 kB)\n",
      "Requirement already satisfied: sklearn==0.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (0.0)\n",
      "Collecting demjson==2.2.4\n",
      "  Using cached demjson-2.2.4-py3-none-any.whl\n",
      "Requirement already satisfied: nltk==3.4.5 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (3.4.5)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (4.60.0)\n",
      "Requirement already satisfied: omegaconf==2.0.1rc4 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (2.0.1rc4)\n",
      "Requirement already satisfied: requests==2.23.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (2.23.0)\n",
      "Requirement already satisfied: torch==1.6.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (1.6.0+cu101)\n",
      "Requirement already satisfied: lmdb==0.98 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (0.98)\n",
      "Requirement already satisfied: numpy>=1.16.6 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from mmf==1.0.0rc12) (1.19.2)\n",
      "Collecting fasttext==0.9.1\n",
      "  Using cached fasttext-0.9.1.tar.gz (57 kB)\n",
      "Requirement already satisfied: pybind11>=2.2 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from fasttext==0.9.1->mmf==1.0.0rc12) (2.6.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from fasttext==0.9.1->mmf==1.0.0rc12) (52.0.0.post20210125)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from GitPython==3.1.0->mmf==1.0.0rc12) (4.0.7)\n",
      "Requirement already satisfied: six in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from nltk==3.4.5->mmf==1.0.0rc12) (1.15.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from omegaconf==2.0.1rc4->mmf==1.0.0rc12) (5.4.1)\n",
      "Requirement already satisfied: dataclasses in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from omegaconf==2.0.1rc4->mmf==1.0.0rc12) (0.8)\n",
      "Requirement already satisfied: typing-extensions in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from omegaconf==2.0.1rc4->mmf==1.0.0rc12) (3.10.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from requests==2.23.0->mmf==1.0.0rc12) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from requests==2.23.0->mmf==1.0.0rc12) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from requests==2.23.0->mmf==1.0.0rc12) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from requests==2.23.0->mmf==1.0.0rc12) (2.10)\n",
      "Requirement already satisfied: scikit-learn in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from sklearn==0.0->mmf==1.0.0rc12) (0.24.2)\n",
      "Requirement already satisfied: future in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from torch==1.6.0->mmf==1.0.0rc12) (0.18.2)\n",
      "Requirement already satisfied: sentencepiece in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from torchtext==0.5.0->mmf==1.0.0rc12) (0.1.95)\n",
      "Requirement already satisfied: pillow>=4.1.1 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from torchvision==0.7.0->mmf==1.0.0rc12) (8.2.0)\n",
      "Requirement already satisfied: packaging in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from transformers==3.4.0->mmf==1.0.0rc12) (20.9)\n",
      "Requirement already satisfied: filelock in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from transformers==3.4.0->mmf==1.0.0rc12) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from transformers==3.4.0->mmf==1.0.0rc12) (2021.4.4)\n",
      "Requirement already satisfied: protobuf in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from transformers==3.4.0->mmf==1.0.0rc12) (3.15.8)\n",
      "Requirement already satisfied: sacremoses in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from transformers==3.4.0->mmf==1.0.0rc12) (0.0.45)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from transformers==3.4.0->mmf==1.0.0rc12) (0.9.2)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython==3.1.0->mmf==1.0.0rc12) (4.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from packaging->transformers==3.4.0->mmf==1.0.0rc12) (2.4.7)\n",
      "Requirement already satisfied: click in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from sacremoses->transformers==3.4.0->mmf==1.0.0rc12) (7.1.2)\n",
      "Requirement already satisfied: joblib in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from sacremoses->transformers==3.4.0->mmf==1.0.0rc12) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\anaconda\\envs\\dl-project\\lib\\site-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (2.1.0)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'done'\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-win_amd64.whl size=192078 sha256=023b7bcc13b88dbd2979a40a0150e0904119ad3036d1ef59f95b5f0a2753b3c4\n",
      "  Stored in directory: c:\\users\\zhang\\appdata\\local\\pip\\cache\\wheels\\ae\\e8\\a0\\03628c77c2e0aa813f067f6d7708a4579d15abf6f45e8716c5\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext, editdistance, demjson, mmf\n",
      "  Running setup.py develop for mmf\n",
      "Successfully installed demjson-2.2.4 editdistance-0.5.3 fasttext-0.9.1 mmf\n"
     ]
    }
   ],
   "source": [
    "!pip install --editable ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyX6Qos3Olyg"
   },
   "source": [
    "---\n",
    "## <font color='magenta'> <b> II. Download the dataset & convert it into *MMF* format </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2fa2bZ6oXIc"
   },
   "source": [
    "### Phase 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvK9KdbloYZJ",
    "outputId": "d4b85b43-72fa-4455-dbf6-3a35984f4869"
   },
   "outputs": [],
   "source": [
    "!wget -O XjiOc5ycDBRRNwbhRlgH.zip --no-check-certificate --no-proxy \"$YOUR_LINK_TO_DOWNLOAD_PHASE2_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TJqJoKnoc1B",
    "outputId": "73b2c361-f68e-4fbf-ff77-01be26069d8a"
   },
   "outputs": [],
   "source": [
    "!mmf_convert_hm --zip_file=\"XjiOc5ycDBRRNwbhRlgH.zip\" --password=$PASSWORD_OF_ZIP --bypass_checksum 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKUDTNzLxvXf"
   },
   "outputs": [],
   "source": [
    "# Free up the disk by removing .zip, .tar files\n",
    "!rm -rf /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/XjiOc5ycDBRRNwbhRlgH.zip\n",
    "!rm -rf $home/mmf/XjiOc5ycDBRRNwbhRlgH.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzAxev4zeXxx"
   },
   "source": [
    "---\n",
    "## <font color='magenta'> <b> III. Feature Extraction </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CTm-rxS0e97"
   },
   "source": [
    "### <font color='lightgreen'> <b> Collect 'pre-extracted' features </b> </font>\n",
    "\n",
    "There are 2 .zip files which stores the extracted image features: one for <font color='Salmon'>Hateful Memes</font>, and one for <font color='Salmon'> Memotion Dataset</font>.\n",
    "\n",
    "The following cell downloads both .zip files into the `$HOME` directory:\n",
    "- [hateful_memes_features](https://drive.google.com/file/d/1YGigTCQQlVvS726YuECTMx0He8p0Xle2/view?usp=sharing)\n",
    "- [memotion_features](https://drive.google.com/file/d/11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6fsV3eBvJgw",
    "outputId": "337aba0b-83a8-4812-e579-ce27503061a3"
   },
   "outputs": [],
   "source": [
    "os.chdir(home)\n",
    "# download HM dataset features\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1YGigTCQQlVvS726YuECTMx0He8p0Xle2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1YGigTCQQlVvS726YuECTMx0He8p0Xle2\" -O 'feats_hm.zip' && rm -rf /tmp/cookies.txt\n",
    "# download Memotion dataset features\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=11o35vKEMDQjvHV42aYMzwjEVlIDZIe1a\" -O 'feats_memotion.zip' && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiSSU9jvccB-",
    "outputId": "7efb4845-89ea-47b3-9def-0858ba08106e"
   },
   "outputs": [],
   "source": [
    "# Unzip features for Memotion dataset & remove it to free disk\n",
    "!unzip $home/feats_memotion.zip -d $home/features/\n",
    "!rm -rf $home/feats_memotion.zip\n",
    "# Unzip features for HM dataset & remove it to free disk\n",
    "!unzip $home/feats_hm.zip -d $home/features/\n",
    "!rm -rf $home/feats_hm.zip\n",
    "# Move Memotion features into the same folder as HM features\n",
    "!mv $home/features/feats_memotion/*.npy $home/features/feats_hm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ19s6lUiL9w"
   },
   "source": [
    "---\n",
    "## <font color='magenta'> <b> IV. Validating'fine-tuned' VisualBERT models on `dev_unseen.jsonl`</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZyV2LQGAgB1"
   },
   "source": [
    "### <font color='Violet'> <b> Submission#1 </b> </font>\n",
    "\n",
    "|            | ROC-AUC | Accuracy |    Dataset   |\n",
    "|------------|:-------:|:--------:|:------------:|\n",
    "|Submission#1| $0.7555$| $0.7352$ | `dev_unseen` |\n",
    "|Submission#1| $0.8108$| $0.7650$ | `test_unseen`|\n",
    "\n",
    "The following cell downloads the fine-tuned model from [this link](https://drive.google.com/file/d/1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2/view?usp=sharing) to the `$HOME` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pi3fDczdwSTg",
    "outputId": "8c4d2872-25c3-4735-c22d-d2f6d690f6f0"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment it if needed\n",
    "\"\"\"\n",
    "\n",
    "# os.chdir(home)\n",
    "# # Download the fine-tuned model\n",
    "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2\" -O 'submission#1.zip' && rm -rf /tmp/cookies.txt\n",
    "# # unzip the model\n",
    "# !unzip -qq $home/submission#1.zip -d $home/submission#1\n",
    "# # remove the .zip after unzipping to free the disk\n",
    "# !rm -rf $home/submission#1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDfafzqZ58iF",
    "outputId": "09b3f01d-50d5-487c-d825-31bccf38c9e9"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment it if needed\n",
    "\"\"\"\n",
    "\n",
    "# # Validate the model on the dev_unseen data\n",
    "# os.chdir(home)\n",
    "# # where checkpoint is\n",
    "# ckpt_dir = os.path.join(home, \"submission#1/best.ckpt\")\n",
    "# feats_dir = os.path.join(home, \"features/feats_hm\")\n",
    "\n",
    "# !mmf_run config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
    "#     model=\"visual_bert\" \\\n",
    "#     dataset=hateful_memes \\\n",
    "#     run_type=val \\\n",
    "#     checkpoint.resume_file=$ckpt_dir \\\n",
    "#     checkpoint.reset.optimizer=True \\\n",
    "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
    "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
    "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
    "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
    "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R12C8XkYBA3q"
   },
   "source": [
    "### <font color='Violet'> <b> Submission#2 </b> </font>\n",
    "\n",
    "|            | ROC-AUC | Accuracy |    Dataset   |\n",
    "|------------|:-------:|:--------:|:------------:|\n",
    "|Submission#2| $0.7757$| $0.7315$ | `dev_unseen` |\n",
    "|Submission#2| $0.8268$| $0.7805$ | `test_unseen`|\n",
    "\n",
    "The following cell downloads the fine-tuned model from [this link](https://drive.google.com/file/d/1To4L0on-Us-DHFn53b21lYYcl6RgaDCB/view?usp=sharing) to the `$HOME` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipPVBLRtwtgI",
    "outputId": "cd657d54-f431-4f99-8546-5678f656e017"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment it if needed\n",
    "\"\"\"\n",
    "\n",
    "# os.chdir(home)\n",
    "# # Download the fine-tuned model\n",
    "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1To4L0on-Us-DHFn53b21lYYcl6RgaDCB' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1To4L0on-Us-DHFn53b21lYYcl6RgaDCB\" -O 'submission#2.zip' && rm -rf /tmp/cookies.txt\n",
    "# # Unzip the model\n",
    "# !unzip -q $home/submission#2.zip -d $home/submission#2\n",
    "# # remove the .zip after unzipping to free the disk\n",
    "# !rm -rf $home/submission#2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kPosRWRChbn",
    "outputId": "3eb1198c-7a89-4c6d-9104-d1a542669de2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment it if needed\n",
    "\"\"\"\n",
    "\n",
    "# os.chdir(home)\n",
    "# # where checkpoint is\n",
    "# ckpt_dir = os.path.join(home, \"submission#2/best.ckpt\")\n",
    "# feats_dir = os.path.join(home, \"features/feats_hm\")\n",
    "\n",
    "# !mmf_run config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
    "#     model=\"visual_bert\" \\\n",
    "#     dataset=hateful_memes \\\n",
    "#     run_type=val \\\n",
    "#     checkpoint.resume_file=$ckpt_dir \\\n",
    "#     checkpoint.reset.optimizer=True \\\n",
    "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
    "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
    "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
    "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
    "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-HsThAZBCCe"
   },
   "source": [
    "### <font color='Violet'> <b> Submission#3 ($Best\\ Submission$)</b> </font>\n",
    "\n",
    "|            | ROC-AUC | Accuracy |    Dataset   |\n",
    "|------------|:-------:|:--------:|:------------:|\n",
    "|Submission#3| $-$     | $-$      | `dev_unseen` |\n",
    "|Submission#3| $0.8518$| $0.8050$ | `test_unseen`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZowowhGDmfvm"
   },
   "source": [
    "After a hyper-parameter search, we ended up having multiple models having different ROC-AUC scores on `dev_unseen` dataset. We sorted them by the ROC score and took all the models that have a ROC score of `0.76` or higher (the threshold is chosen arbitrarily). The following figure shows all the $27$ models and its ROC-scores, as well as its hyper-parameters ([see this document for all the model scores, 60+ models in total](https://docs.google.com/spreadsheets/d/11m2p7vNxHhZWumkFNvv6d94HcqG77DItRX7MuGfOtWA/edit?usp=sharing)).\n",
    "\n",
    "<details><summary>\n",
    "<font color='Tan'> Figure 1: ROC-AUC scores (on `dev_unseen`) of different VisualBERT models </font></summary>\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=10WUBnSO5L5O44c8WCxHRA_iFZudH73lF\" width=\"1000\"> \n",
    "\n",
    "</details>\n",
    "\n",
    "Then, predictions are collected from each of the $27$ models and the `Majority Voting` technique is applied: the `class` of a data point is determined by the majority voted class.\n",
    "\n",
    "> This technique is also known as: [Voting classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html), [Ensemble learning](https://en.wikipedia.org/wiki/Ensemble_learning), [Bootstrap Aggregating (BAGGING)](https://en.wikipedia.org/wiki/Bootstrap_aggregating#:~:text=Bootstrap%20aggregating%2C%20also%20called%20bagging,and%20helps%20to%20avoid%20overfitting.)\n",
    "\n",
    "Please see [this document](https://drive.google.com/file/d/1vjUsMqaqjZdoNj0w989RX7GKkPod-CGo/view?usp=sharing) to see all the model predictions for `test_unseen` and how the technique is applied.\n",
    "\n",
    "**Note:**  The `proba` column in the submission which stands for the probability of a data point belonging to a class is chosen to be the maximum probability among all of the $27$ models if $Class\\ 1$, and the minumum if $Class\\ 0$.\n",
    "\n",
    "See the Part<font color='magenta'> <b> V. Generate predictions for the Challenge (`test_unseen.jsonl`) </b> </font> for the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBhK1UPCcLCd"
   },
   "source": [
    "---\n",
    "## <font color='magenta'> <b> V. Generate predictions for the Challenge (`test_unseen.jsonl`) </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8zO7Tj98Nfp"
   },
   "source": [
    "### <font color='Thistle'> <b> Submission#1 </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmaeQY_GcS93",
    "outputId": "a9953343-1915-4a66-b120-b42f668c9911"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment it if needed\n",
    "\"\"\"\n",
    "\n",
    "# os.chdir(home)\n",
    "# # where checkpoint is\n",
    "# ckpt_dir = os.path.join(home, \"submission#1/best.ckpt\")\n",
    "# feats_dir = os.path.join(home, \"features/feats_hm\")\n",
    "\n",
    "# !mmf_predict config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
    "#     model=\"visual_bert\" \\\n",
    "#     dataset=hateful_memes \\\n",
    "#     run_type=test \\\n",
    "#     checkpoint.resume_file=$ckpt_dir \\\n",
    "#     checkpoint.reset.optimizer=True \\\n",
    "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
    "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
    "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
    "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
    "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPz2PsmU8jU-"
   },
   "source": [
    "### <font color='Thistle'> <b> Submission#2 </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HR3nPRV8jU_",
    "outputId": "4d227084-48c9-4dfa-bda1-15c0e5fa567c"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment it if needed\n",
    "\"\"\"\n",
    "\n",
    "# os.chdir(home)\n",
    "# # where checkpoint is\n",
    "# ckpt_dir = os.path.join(home, \"submission#2/best.ckpt\")\n",
    "# feats_dir = os.path.join(home, \"features/feats_hm\")\n",
    "\n",
    "# !mmf_predict config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
    "#     model=\"visual_bert\" \\\n",
    "#     dataset=hateful_memes \\\n",
    "#     run_type=test \\\n",
    "#     checkpoint.resume_file=$ckpt_dir \\\n",
    "#     checkpoint.reset.optimizer=True \\\n",
    "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
    "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
    "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
    "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
    "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAK66Ottxdwv"
   },
   "source": [
    "### <font color='Thistle'> <b> Submission#3  ($Best\\ Submission$)</b> </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0veOdd4QYwDa",
    "outputId": "dec9dff0-8858-44b6-c046-d876d60373e1"
   },
   "outputs": [],
   "source": [
    "os.mkdir(f\"{home}/sub3/\")\n",
    "os.chdir(os.path.join(home, \"sub3\"))\n",
    "!git clone https://github.com/rizavelioglu/hateful_memes-hate_detectron.git\n",
    "!cp hateful_memes-hate_detectron/utils/generate_submission.sh .\n",
    "!chmod +x generate_submission.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-9rsMTMYwDa"
   },
   "source": [
    "Download 27 models in a `.7z` file and extract them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QFh5YY-YwDa"
   },
   "outputs": [],
   "source": [
    "# Download the .7z file which includes all the 27 models\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1D1nehiowEHMxJwijybfuTiC1835wZaHk' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1D1nehiowEHMxJwijybfuTiC1835wZaHk\" -O 'majority_voting_models.7z' && rm -rf /tmp/cookies.txt\n",
    "# Extract the .7z file to get the models\n",
    "# !p7zip -d 'majority_voting_models.7z'\n",
    "# !sudo apt-get install p7zip-full p7zip-rar\n",
    "!7z e 'majority_voting_models.7z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnqJyYjTYwDa"
   },
   "source": [
    "Generate submission for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4bF8UbJYwDa"
   },
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "\n",
    "models = [i for i in os.listdir(\".\") if i.endswith(\".ckpt\")]\n",
    "\n",
    "print(f\"[INFO] Getting predictions for {len(models)} models! This might take long..\")\n",
    "for model in models:\n",
    "    feats_dir = os.path.join(home, \"features/feats_hm\")\n",
    "    # Execute the bash script which gets predictions for 'test_unseen' data\n",
    "    rc = call(f\"./generate_submission.sh {model} {feats_dir}\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A40AWbCuYwDa"
   },
   "source": [
    "Apply majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zQCkM-_YwDa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Store all the prediction folders\n",
    "folders = [i for i in os.listdir(\"save/preds\") if i.startswith(\"hateful_memes\")]\n",
    "preds = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    for folder in folders:\n",
    "        pred = [i for i in os.listdir(f\"save/preds/{folder}/reports/\") if i.endswith(\".csv\")]\n",
    "        pred = pd.read_csv(f\"save/preds/{folder}/reports/{pred[0]}\")\n",
    "        preds = pd.concat([preds, pred], axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# assert len(preds.columns) == 27*3\n",
    "\n",
    "# Create \n",
    "submission = pred\n",
    "np_df = np.asarray(preds)\n",
    "\n",
    "for idx, row in enumerate(np_df[:,:]):\n",
    "    probas = row[1::3]\n",
    "    labels = row[2::3]\n",
    "\n",
    "    if sum(labels) > 13:\n",
    "        submission.loc[idx, 'label']=1\n",
    "        submission.loc[idx, 'proba']=probas.max()    \n",
    "    else:\n",
    "        submission.loc[idx, 'label']=0\n",
    "        submission.loc[idx, 'proba']=probas.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5KKjmibYwDa"
   },
   "source": [
    "Sort the submission with regards to the submission template & save the final submission file to `submission#3.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "od8EOLEiYwDa",
    "outputId": "d14492c2-33d4-4225-8d73-4031c33fcbb3"
   },
   "outputs": [],
   "source": [
    "# Download the Phase2 submission template\n",
    "!wget -O submission_format_phase_2.csv  \"https://drivendata-prod.s3.amazonaws.com/data/70/public/submission_format_phase_2.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYVI2LMPSY%2F20201201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201201T023533Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=04330cf22c33f1817cac29509178d2c11a07d620e8237241c5088f4fd25df2b3\"\n",
    "os.chdir(os.path.join(home, \"sub3\"))\n",
    "template = pd.read_csv(\"submission_format_phase_2.csv\")\n",
    "# Sort the 'submission' file\n",
    "submission = submission.set_index('id')\n",
    "submission = submission.reindex(index=template['id'])\n",
    "submission = submission.reset_index()\n",
    "# Save submission file\n",
    "submission.to_csv(f\"{home}/submission#3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kE9_rJZfF_Rf",
    "rna7NAZtwaod",
    "FyX6Qos3Olyg",
    "LzAxev4zeXxx",
    "0CTm-rxS0e97",
    "OJ19s6lUiL9w",
    "6ZyV2LQGAgB1",
    "R12C8XkYBA3q",
    "o-HsThAZBCCe",
    "CBhK1UPCcLCd",
    "F8zO7Tj98Nfp",
    "VPz2PsmU8jU-",
    "FAK66Ottxdwv"
   ],
   "name": "[GitHub]reproduce_submissions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
