{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d6a7d7",
   "metadata": {},
   "source": [
    "# process memotion dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be496ac9",
   "metadata": {},
   "source": [
    "### 1. remove crashed images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8526f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "home = '/home/chen_zhang06/HatefulMemes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1141e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(memo):\n",
    "    import re\n",
    "    from collections import Counter\n",
    "\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text_to_remove = [\"imgflip.com\", \"imgflip\", \"quickmeme.com\", \"quickmeme\",\n",
    "                      \"memecenter.com\", \"memecenter\", \"memegenerator.net\",\n",
    "                      \"memegenerator\", \"9gag.com\", \"arhtisticlicense.com\",\n",
    "                      \"starecat.com\", \"gapbagap.net\", \"dudelol.com\"]\n",
    "\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(text_to_remove))\n",
    "\n",
    "    memo.text = memo.text.str.lower()\n",
    "    # Remove URLs\n",
    "    memo.text = memo.text.str.replace(url_pattern, \"\")\n",
    "    # Remove words in 'text_to_remove'\n",
    "    memo.text = memo.text.str.replace(pat, '')\n",
    "    # Remove any character that's not a letter or a number\n",
    "    memo.text = memo.text.replace(r\"[\\W_]+\", \" \", regex=True)\n",
    "    memo = memo.dropna()\n",
    "    return memo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting csv and image data\n",
    "path2img = os.path.join(home, \"memotion_dataset_7k/images/\")\n",
    "path2data = os.path.join(home, \"memotion_dataset_7k/labels.csv\")\n",
    "df = pd.read_csv(path2data, delimiter=',')\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns: \\n {list(df.columns)}\\n')\n",
    "print('--------------', df[\"offensive\"].unique())\n",
    "# print(df.head)\n",
    "\n",
    "for i in df[\"offensive\"].unique():\n",
    "    print(f\"# of '{i}' memes \\t: {len(df[df['offensive']==i])}\")\n",
    "\n",
    "columns = [\"image_name\", \"text_corrected\", 'offensive']\n",
    "# hateful_offensive = df[df[\"offensive\"]==\"hateful_offensive\"][columns]\n",
    "hateful_offensive = df[df[\"offensive\"].isin(df[\"offensive\"].unique())][columns]\n",
    "# print(hateful_offensive)\n",
    "# very_offensive    = df[df[\"offensive\"]==\"very_offensive\"][columns]\n",
    "# not_offensive          = df[df[\"offensive\"]==\"not_offensive\"][columns]\n",
    "\n",
    "memo = df[columns]\n",
    "memo.columns = [\"id\", \"text\", 'label']\n",
    "print(memo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadcf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate empty or mismatched files: \n",
    "img_dir = os.path.join(home, 'memotion_dataset_7k/images/')\n",
    "emptyfile = []\n",
    "for i in memo['id']: \n",
    "    try: \n",
    "        path = os.path.join(img_dir, i)\n",
    "        img = Image.open(path)\n",
    "        im = np.array(img).astype(np.float32)\n",
    "    except: \n",
    "        emptyfile.append(i)\n",
    "print(len(emptyfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f7c4e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4155, 3)\n",
      "(4155, 3)\n"
     ]
    }
   ],
   "source": [
    "# remove those lines in the pd file, and remove the 'slight' offensive category, as it might be confusing\n",
    "print(memo.shape)\n",
    "memo.drop(memo[memo['id'].isin(emptyfile)].index, inplace = True)\n",
    "memo.drop(memo[memo['label'] == 'slight'].index, inplace = True)\n",
    "print(memo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c49074d",
   "metadata": {},
   "source": [
    "### 2. Re-assign label values, move those images to another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29adbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then re-assign the label value: \n",
    "hatefullist = ['hateful_offensive', 'very_offensive']\n",
    "# nonhatefullist = ['not_offensive', 'slight', 'very_offensive']\n",
    "nonhatefullist = ['not_offensive']\n",
    "memo.loc[memo['label'].isin(hatefullist), 'label'] = 1\n",
    "memo.loc[memo['label'].isin(nonhatefullist), 'label'] = 0\n",
    "\n",
    "# Add missing columns so it looks like Hateful Memes data\n",
    "memo[\"img\"] = (\"img/\" + memo[\"id\"])\n",
    "memo[\"img\"] = memo[\"img\"].str.lower()\n",
    "# remove extension in \"image_name\" & get the number of the image & add 100k, cause the HM data ID's goes up to 99k\n",
    "memo[\"id\"] = memo[\"id\"].str.split(\".\").str.get(0).str.split(\"_\").str.get(1).astype(int) + 100_000\n",
    "# Re-order columns\n",
    "memo = memo[[\"id\", \"img\", 'label', \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7d0aee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img label  \\\n",
      "0     100001     img/image_1.jpg     0   \n",
      "1     100002    img/image_2.jpeg     0   \n",
      "2     100003     img/image_3.jpg     0   \n",
      "3     100004     img/image_4.png     1   \n",
      "4     100005     img/image_5.png     1   \n",
      "...      ...                 ...   ...   \n",
      "6986  106987  img/image_6987.jpg     0   \n",
      "6987  106988  img/image_6988.jpg     1   \n",
      "6988  106989  img/image_6989.jpg     0   \n",
      "6990  106991  img/image_6991.jpg     0   \n",
      "6991  106992  img/image_6992.jpg     0   \n",
      "\n",
      "                                                   text  \n",
      "0     look there my friend lightyear now all sohalik...  \n",
      "1     the best of 10 yearchallenge completed in less...  \n",
      "2     sam thorne strippin follow follow saw everyone...  \n",
      "3                   10 year challenge sweet dee edition  \n",
      "4     10 year challenge with no filter 47 hilarious ...  \n",
      "...                                                 ...  \n",
      "6986  if you re going on and on and on about your pr...  \n",
      "6987  tuesday is mardi gras wednesday is valentine s...  \n",
      "6988  must watch movies of 2017 iti chennai memes ma...  \n",
      "6990  when i have time is a fantasy no one has time ...  \n",
      "6991  the starting point for every good idea is what...  \n",
      "\n",
      "[4151 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "# Pre-process the text in memes\n",
    "memo = preprocess_text(memo)\n",
    "print(memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e78185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy these files into another folder: memotion_dataset_7k/images_selected/\n",
    "import zipfile\n",
    "flist = list(memo['img'].str.split('/').str.get(1))\n",
    "# print(flist)\n",
    "\n",
    "import os\n",
    "os.chdir(os.path.join(home, 'memotion_dataset_7k/images/'))\n",
    "with zipfile.ZipFile('memotion_selected.zip', 'w') as zipMe:        \n",
    "    for file in flist:\n",
    "        try: \n",
    "            zipMe.write(file, compress_type=zipfile.ZIP_DEFLATED)\n",
    "        except: pass\n",
    "!mv memotion_selected.zip ../images_selected/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(home, 'memotion_dataset_7k/images_selected/'))\n",
    "!unzip memotion_selected.zip\n",
    "# !rm -rf memotion_selected.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7f6c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf memotion_selected.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "812f4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4138\n"
     ]
    }
   ],
   "source": [
    "# check number of images: 4138\n",
    "!ls -F | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffbffd",
   "metadata": {},
   "source": [
    "### 3. generate jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "490b1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = memo.to_json(orient='records', lines=True)\n",
    "with open(os.path.join(home, \"annotations/label_memotion.jsonl\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1059d2",
   "metadata": {},
   "source": [
    "# double check jsonl file and selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb8c2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img  label  \\\n",
      "0     100001     img/image_1.jpg      0   \n",
      "1     100002    img/image_2.jpeg      0   \n",
      "2     100003     img/image_3.jpg      0   \n",
      "3     100004     img/image_4.png      1   \n",
      "4     100005     img/image_5.png      1   \n",
      "...      ...                 ...    ...   \n",
      "4146  106987  img/image_6987.jpg      0   \n",
      "4147  106988  img/image_6988.jpg      1   \n",
      "4148  106989  img/image_6989.jpg      0   \n",
      "4149  106991  img/image_6991.jpg      0   \n",
      "4150  106992  img/image_6992.jpg      0   \n",
      "\n",
      "                                                   text  \n",
      "0     look there my friend lightyear now all sohalik...  \n",
      "1     the best of 10 yearchallenge completed in less...  \n",
      "2     sam thorne strippin follow follow saw everyone...  \n",
      "3                   10 year challenge sweet dee edition  \n",
      "4     10 year challenge with no filter 47 hilarious ...  \n",
      "...                                                 ...  \n",
      "4146  if you re going on and on and on about your pr...  \n",
      "4147  tuesday is mardi gras wednesday is valentine s...  \n",
      "4148  must watch movies of 2017 iti chennai memes ma...  \n",
      "4149  when i have time is a fantasy no one has time ...  \n",
      "4150  the starting point for every good idea is what...  \n",
      "\n",
      "[4151 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "home = '/home/chen_zhang06/HatefulMemes/'\n",
    "memotion = pd.read_json(os.path.join(home, \"annotations/label_memotion.jsonl\"), lines=True)\n",
    "print(memotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6497c",
   "metadata": {},
   "source": [
    "4151 rows in the memotion, but only 4138 files in the images_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2205af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = memotion['img']\n",
    "# print(fnames)\n",
    "img_names = list(fnames.str.split('/').str.get(1))\n",
    "# print(img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9441bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4138\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = os.path.join(home, \"memotion_dataset_7k/images_selected/\")\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(len(onlyfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e26249b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_3.jpg', 'image_284.png', 'image_534.jpg', 'image_762.jpg', 'image_763.jpg', 'image_1615.png', 'image_2743.jpg', 'image_4321.jpg', 'image_4631.jpg', 'image_5245.jpg', 'image_5371.jpg', 'image_5493.jpg', 'image_5635.jpg'] 13\n"
     ]
    }
   ],
   "source": [
    "diff = [f for f in img_names if f not in onlyfiles]\n",
    "print(diff, len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98c757a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img  label  \\\n",
      "0     100001     img/image_1.jpg      0   \n",
      "1     100002    img/image_2.jpeg      0   \n",
      "3     100004     img/image_4.png      1   \n",
      "4     100005     img/image_5.png      1   \n",
      "5     100008     img/image_8.jpg      0   \n",
      "...      ...                 ...    ...   \n",
      "4146  106987  img/image_6987.jpg      0   \n",
      "4147  106988  img/image_6988.jpg      1   \n",
      "4148  106989  img/image_6989.jpg      0   \n",
      "4149  106991  img/image_6991.jpg      0   \n",
      "4150  106992  img/image_6992.jpg      0   \n",
      "\n",
      "                                                   text  \n",
      "0     look there my friend lightyear now all sohalik...  \n",
      "1     the best of 10 yearchallenge completed in less...  \n",
      "3                   10 year challenge sweet dee edition  \n",
      "4     10 year challenge with no filter 47 hilarious ...  \n",
      "5     10 year challenge emotional edition boredpanda...  \n",
      "...                                                 ...  \n",
      "4146  if you re going on and on and on about your pr...  \n",
      "4147  tuesday is mardi gras wednesday is valentine s...  \n",
      "4148  must watch movies of 2017 iti chennai memes ma...  \n",
      "4149  when i have time is a fantasy no one has time ...  \n",
      "4150  the starting point for every good idea is what...  \n",
      "\n",
      "[4138 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# remove those lines in pd: \n",
    "memotion.drop(memotion[memotion['img'].str.split('/').str.get(1).isin(diff)].index, inplace = True)\n",
    "print(memotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f498008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a new jsonl file: \n",
    "\n",
    "# data = memotion.to_json(orient='records', lines=True)\n",
    "# with open(os.path.join(home, \"annotations/memotion_selected.jsonl\"), \"w\", encoding='utf-8') as f:\n",
    "#     f.write(data)\n",
    "    \n",
    "# rename image as selected 1\n",
    "memotion['img'] = memotion['img'].str.split('/').str.get(1)\n",
    "# print(memotion['img'].str.split('/').str.get(1))\n",
    "# print(memotion)\n",
    "data = memotion.to_json(orient='records', lines=True)\n",
    "with open(os.path.join(home, \"annotations/memotion_selected1.jsonl\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48e48bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model and config file exists in directory: /home/chen_zhang06/HatefulMemes/mmf/tools/scripts/features\n",
      "image directory: /home/chen_zhang06/HatefulMemes/memotion_dataset_7k/images_selected\n",
      "/home/chen_zhang06/HatefulMemes/vqa-maskrcnn-benchmark/maskrcnn_benchmark/structures/boxlist_ops.py:45: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  keep = ((ws >= min_size) & (hs >= min_size)).nonzero().squeeze(1)\n",
      "Processed 200/4137\n",
      "Processed 400/4137\n",
      "Processed 600/4137\n",
      "/opt/conda/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "Processed 800/4137\n",
      "Processed 1000/4137\n",
      "/opt/conda/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:793: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "Processed 1200/4137\n",
      "Processed 1400/4137\n",
      "Processed 1600/4137\n",
      "Processed 1800/4137\n",
      "Processed 2000/4137\n",
      "Processed 2200/4137\n",
      "Processed 2400/4137\n",
      "Processed 2600/4137\n",
      "Processed 2800/4137\n",
      "Processed 3000/4137\n",
      "Processed 3200/4137\n",
      "Processed 3400/4137\n",
      "Processed 3600/4137\n",
      "Processed 3800/4137\n",
      "Processed 4000/4137\n"
     ]
    }
   ],
   "source": [
    "# extract all features for those 4k images: \n",
    "import os\n",
    "home = \"/home/chen_zhang06/HatefulMemes\"\n",
    "os.chdir(os.path.join(home, \"mmf/tools/scripts/features/\"))\n",
    "out_folder = os.path.join(home, \"features_memo_4k/\")\n",
    "\n",
    "!python extract_features_vmb.py --config_file \"https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model_x152.yaml\" \\\n",
    "                                --model_name \"X-152\" \\\n",
    "                                --output_folder $out_folder \\\n",
    "                                --image_dir \"/home/chen_zhang06/HatefulMemes/memotion_dataset_7k/images_selected\" \\\n",
    "                                --num_features 100 \\\n",
    "                                # --exclude_list \"/content/exclude.txt\"\n",
    "                                # --feature_name \"fc6\" \\\n",
    "                                # --confidence_threshold 0. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59488fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the submission1 best model to predict:\n",
    "\n",
    "os.chdir(home)\n",
    "# Download the fine-tuned model\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1NOX2lJkbK7sKRsg4_y_KUcLamknowsu2\" -O 'submission#1.zip' && rm -rf /tmp/cookies.txt\n",
    "# unzip the model\n",
    "!unzip -qq $home/submission#1.zip -d $home/submission#1\n",
    "# remove the .zip after unzipping to free the disk\n",
    "!rm -rf $home/submission#1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check if all jsonl files and memotion features matched up .... 3616 is an issue\n",
    "\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# mypath = os.path.join(home, \"memotion_dataset_7k/images_selected/\")\n",
    "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "# print(len(onlyfiles))\n",
    "\n",
    "home = '/home/chen_zhang06/HatefulMemes/'\n",
    "memo = pd.read_json(os.path.join(home, \"annotations/memotion_selected.jsonl\"), lines=True)\n",
    "print(memo)\n",
    "# f_list = list(memotion['img'].str.split('/').str.get(1))\n",
    "memo.drop(memo[memo['id'] == 103616].index, inplace = True)\n",
    "print(memo) # 3616 removed...\n",
    "# save again\n",
    "\n",
    "data = memo.to_json(orient='records', lines=True)\n",
    "with open(os.path.join(home, \"annotations/memotion_selected1.jsonl\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment it if needed\n",
    "\"\"\"\n",
    "\n",
    "# Validate the model on the dev_unseen data\n",
    "os.chdir(home)\n",
    "# where checkpoint is\n",
    "ckpt_dir = os.path.join(home, \"submission#1/best.ckpt\")\n",
    "feats_dir = os.path.join(home, \"features/feats_hm\")\n",
    "\n",
    "!mmf_run config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\"\\\n",
    "    model=\"visual_bert\"\\\n",
    "    dataset=hateful_memes\\\n",
    "    run_type=val\\\n",
    "    checkpoint.resume_file=$ckpt_dir\\\n",
    "    checkpoint.reset.optimizer=True\\\n",
    "    dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/memotion_selected1.jsonl\\\n",
    "    dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl\\\n",
    "    dataset_config.hateful_memes.features.train[0]=$feats_dir\\\n",
    "    dataset_config.hateful_memes.features.val[0]=$feats_dir\\\n",
    "    dataset_config.hateful_memes.features.test[0]=$feats_dir\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0684250",
   "metadata": {},
   "source": [
    "2021-05-04T14:40:26 | mmf.trainers.callbacks.logistics: val/hateful_memes/cross_entropy: 1.9090, val/total_loss: 1.9090, val/hateful_memes/accuracy: 0.5857, val/hateful_memes/binary_f1: 0.2606, val/hateful_memes/roc_auc: 0.5084\n",
    "This means that the memotion dataset is poorly labelled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f168124",
   "metadata": {},
   "source": [
    "Get test results for those images! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5de86346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best-0.ckpt', 'best-1.ckpt', 'best-2.ckpt', 'best-3.ckpt', 'best-4.ckpt', 'best-5.ckpt', 'best-6.ckpt', 'best-7.ckpt', 'best-8.ckpt', 'best-9.ckpt', 'best-10.ckpt', 'best-11.ckpt', 'best-12.ckpt', 'best-13.ckpt', 'best-14.ckpt', 'best-15.ckpt', 'best-16.ckpt', 'best-17.ckpt', 'best-18.ckpt', 'best-19.ckpt', 'best-20.ckpt', 'best-21.ckpt', 'best-22.ckpt', 'best-23.ckpt', 'best-24.ckpt', 'best-25.ckpt', 'best-26.ckpt']\n",
      "[INFO] Getting predictions for 27 models! This might take long..\n",
      "Running ./majority_voting_models/best-0.ckpt\n",
      "Running ./majority_voting_models/best-1.ckpt\n",
      "Running ./majority_voting_models/best-2.ckpt\n",
      "Running ./majority_voting_models/best-3.ckpt\n",
      "Running ./majority_voting_models/best-4.ckpt\n",
      "Running ./majority_voting_models/best-5.ckpt\n",
      "Running ./majority_voting_models/best-6.ckpt\n",
      "Running ./majority_voting_models/best-7.ckpt\n",
      "Running ./majority_voting_models/best-8.ckpt\n",
      "Running ./majority_voting_models/best-9.ckpt\n",
      "Running ./majority_voting_models/best-10.ckpt\n",
      "Running ./majority_voting_models/best-11.ckpt\n",
      "Running ./majority_voting_models/best-12.ckpt\n",
      "Running ./majority_voting_models/best-13.ckpt\n",
      "Running ./majority_voting_models/best-14.ckpt\n",
      "Running ./majority_voting_models/best-15.ckpt\n",
      "Running ./majority_voting_models/best-16.ckpt\n",
      "Running ./majority_voting_models/best-17.ckpt\n",
      "Running ./majority_voting_models/best-18.ckpt\n",
      "Running ./majority_voting_models/best-19.ckpt\n",
      "Running ./majority_voting_models/best-20.ckpt\n",
      "Running ./majority_voting_models/best-21.ckpt\n",
      "Running ./majority_voting_models/best-22.ckpt\n",
      "Running ./majority_voting_models/best-23.ckpt\n",
      "Running ./majority_voting_models/best-24.ckpt\n",
      "Running ./majority_voting_models/best-25.ckpt\n",
      "Running ./majority_voting_models/best-26.ckpt\n",
      "finished!\n",
      "2.4318695068359375e-05\n"
     ]
    }
   ],
   "source": [
    "from subprocess import call\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# home = \"/home/jupyter/HatefulMemes\"\n",
    "home = \"/home/chen_zhang06/HatefulMemes\"\n",
    "os.chdir(home)\n",
    "\n",
    "# models = [i for i in os.listdir(\"./majority_voting_models\") if i.endswith(\".ckpt\")]\n",
    "\n",
    "# models = ['best-' + str(i) + '.ckpt' for i in range(0, 27)]\n",
    "# try only 11 models first! \n",
    "models = ['best-' + str(i) + '.ckpt' for i in range(0, 27)]\n",
    "print(models)\n",
    "\n",
    "print(f\"[INFO] Getting predictions for {len(models)} models! This might take long..\")\n",
    "for model in models:\n",
    "    model = \"./majority_voting_models/\" + model \n",
    "    feats_dir = os.path.join(home, \"features/feats_hm\")\n",
    "    # Execute the bash script which gets predictions for 'test_unseen' data\n",
    "    print(f\"Running \" + model)\n",
    "    rc = call(f\"./generate_submission.sh {model} {feats_dir}\", shell=True)\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fa2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id     proba  label\n",
      "0     100001  0.000098      0\n",
      "1     100002  0.000906      0\n",
      "2     100004  0.000589      0\n",
      "3     100005  0.000014      0\n",
      "4     100008  0.000029      0\n",
      "...      ...       ...    ...\n",
      "4132  106987  0.000012      0\n",
      "4133  106988  0.000185      0\n",
      "4134  106989  0.000022      0\n",
      "4135  106991  0.000011      0\n",
      "4136  106992  0.000017      0\n",
      "\n",
      "[4137 rows x 3 columns]\n",
      "0    3365\n",
      "1     772\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# home = \"/home/jupyter/HatefulMemes\"\n",
    "home = \"/home/chen_zhang06/HatefulMemes\"\n",
    "os.chdir(home)\n",
    "\n",
    "# Store all the prediction folders\n",
    "folders = [i for i in os.listdir(\"save/preds\") if i.startswith(\"hateful_memes\")]\n",
    "# print(folders)\n",
    "preds = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    for folder in folders:\n",
    "        pred = [i for i in os.listdir(f\"save/preds/{folder}/reports/\") if i.endswith(\".csv\")]\n",
    "#         print(pred)\n",
    "        pred = pd.read_csv(f\"save/preds/{folder}/reports/{pred[0]}\")\n",
    "        preds = pd.concat([preds, pred], axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# print(preds)\n",
    "\n",
    "# assert len(preds.columns) == 27*3\n",
    "\n",
    "# Create \n",
    "submission = pred\n",
    "np_df = np.asarray(preds)\n",
    "\n",
    "for idx, row in enumerate(np_df[:,:]):\n",
    "    probas = row[1::3]\n",
    "    labels = row[2::3]\n",
    "\n",
    "    if sum(labels) > 13:\n",
    "        submission.loc[idx, 'label']=1\n",
    "        submission.loc[idx, 'proba']=probas.max()    \n",
    "    else:\n",
    "        submission.loc[idx, 'label']=0\n",
    "        submission.loc[idx, 'proba']=probas.min()\n",
    "\n",
    "print(submission)\n",
    "print(submission['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef13e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv: \n",
    "submission.to_csv(\"save/preds/voting.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb619720",
   "metadata": {},
   "source": [
    "# compare the prediciton from the best model (27 models, majority voting) wiht initial labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce09e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "home = '/home/chen_zhang06/HatefulMemes/'\n",
    "memotion = pd.read_json(os.path.join(home, \"annotations/memotion_selected1.jsonl\"), lines=True)\n",
    "# print(memotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556fa289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pred_id     proba  pred_label\n",
      "0      100001  0.000098           0\n",
      "1      100002  0.000906           0\n",
      "2      100004  0.000589           0\n",
      "3      100005  0.000014           0\n",
      "4      100008  0.000029           0\n",
      "...       ...       ...         ...\n",
      "4132   106987  0.000012           0\n",
      "4133   106988  0.000185           0\n",
      "4134   106989  0.000022           0\n",
      "4135   106991  0.000011           0\n",
      "4136   106992  0.000017           0\n",
      "\n",
      "[4137 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pred = pd.read_csv(os.path.join(home, \"save/preds/voting.csv\"))\n",
    "pred.columns = [\"pred_id\", \"proba\", 'pred_label']\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633589ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([memotion, pred], axis=1, join=\"inner\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those lines that the model prediction does not match with orinigal label\n",
    "result.drop(result[result['label'] != result['pred_label']].index, inplace = True)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c13d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img  label  \\\n",
      "0     100001     img/image_1.jpg      0   \n",
      "1     100002    img/image_2.jpeg      0   \n",
      "4     100008     img/image_8.jpg      0   \n",
      "7     100013    img/image_13.png      0   \n",
      "8     100014    img/image_14.png      0   \n",
      "...      ...                 ...    ...   \n",
      "4131  106986  img/image_6986.jpg      0   \n",
      "4132  106987  img/image_6987.jpg      0   \n",
      "4134  106989  img/image_6989.jpg      0   \n",
      "4135  106991  img/image_6991.jpg      0   \n",
      "4136  106992  img/image_6992.jpg      0   \n",
      "\n",
      "                                                   text  \n",
      "0     look there my friend lightyear now all sohalik...  \n",
      "1     the best of 10 yearchallenge completed in less...  \n",
      "4     10 year challenge emotional edition boredpanda...  \n",
      "7     i did the facebook 10 year challenge and it wa...  \n",
      "8     ifidownloada movie in jamaica memes in 2009 am...  \n",
      "...                                                 ...  \n",
      "4131  what oils are good por cutting that poul smell...  \n",
      "4132  if you re going on and on and on about your pr...  \n",
      "4134  must watch movies of 2017 iti chennai memes ma...  \n",
      "4135  when i have time is a fantasy no one has time ...  \n",
      "4136  the starting point for every good idea is what...  \n",
      "\n",
      "[2390 rows x 4 columns]\n",
      "0    2114\n",
      "1     276\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns = ['id', 'img', 'label', 'text']\n",
    "output = result[columns]\n",
    "print(output)\n",
    "print(output['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9a5b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img  label  \\\n",
      "16    100027   img/image_27.jpeg      1   \n",
      "59    100089    img/image_89.jpg      1   \n",
      "70    100105   img/image_105.png      1   \n",
      "100   100153   img/image_153.png      1   \n",
      "102   100158   img/image_158.jpg      1   \n",
      "...      ...                 ...    ...   \n",
      "4065  106880  img/image_6880.jpg      1   \n",
      "4079  106900  img/image_6900.jpg      1   \n",
      "4093  106923  img/image_6923.jpg      1   \n",
      "4113  106955  img/image_6955.jpg      1   \n",
      "4130  106985  img/image_6985.jpg      1   \n",
      "\n",
      "                                                   text  \n",
      "16    i wonder why who s that they call him hawkeye ...  \n",
      "59         women get over here this instant hmm not bad  \n",
      "70    to be continued baby godfather challange gone ...  \n",
      "100   best of barney i only have one rule never scre...  \n",
      "102   mr mime the barrier pokemon known to make wall...  \n",
      "...                                                 ...  \n",
      "4065  silly girl art base 3 6 dec thats not the kitc...  \n",
      "4079  you ve been hit by you ve been struck by a smo...  \n",
      "4093  when you get tired of going to work every day ...  \n",
      "4113  what do you call a cow falling off a cliff led...  \n",
      "4130  you re the best around nothing s ever gonna ke...  \n",
      "\n",
      "[276 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# select total 1000 images for training: \n",
    "# get the hateful ones: \n",
    "hateful_df = output[output['label'] == 1]\n",
    "print(hateful_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bac1b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img  label  \\\n",
      "0     100001     img/image_1.jpg      0   \n",
      "1     100002    img/image_2.jpeg      0   \n",
      "4     100008     img/image_8.jpg      0   \n",
      "7     100013    img/image_13.png      0   \n",
      "8     100014    img/image_14.png      0   \n",
      "...      ...                 ...    ...   \n",
      "4131  106986  img/image_6986.jpg      0   \n",
      "4132  106987  img/image_6987.jpg      0   \n",
      "4134  106989  img/image_6989.jpg      0   \n",
      "4135  106991  img/image_6991.jpg      0   \n",
      "4136  106992  img/image_6992.jpg      0   \n",
      "\n",
      "                                                   text  \n",
      "0     look there my friend lightyear now all sohalik...  \n",
      "1     the best of 10 yearchallenge completed in less...  \n",
      "4     10 year challenge emotional edition boredpanda...  \n",
      "7     i did the facebook 10 year challenge and it wa...  \n",
      "8     ifidownloada movie in jamaica memes in 2009 am...  \n",
      "...                                                 ...  \n",
      "4131  what oils are good por cutting that poul smell...  \n",
      "4132  if you re going on and on and on about your pr...  \n",
      "4134  must watch movies of 2017 iti chennai memes ma...  \n",
      "4135  when i have time is a fantasy no one has time ...  \n",
      "4136  the starting point for every good idea is what...  \n",
      "\n",
      "[2114 rows x 4 columns]\n",
      "          id                 img  label  \\\n",
      "285   100446   img/image_446.jpg      0   \n",
      "2977  105078  img/image_5078.png      0   \n",
      "1239  102153  img/image_2153.png      0   \n",
      "665   101164  img/image_1164.jpg      0   \n",
      "2719  104650  img/image_4650.jpg      0   \n",
      "...      ...                 ...    ...   \n",
      "1982  103425  img/image_3425.jpg      0   \n",
      "1465  102533  img/image_2533.jpg      0   \n",
      "2501  104283  img/image_4283.jpg      0   \n",
      "2588  104444  img/image_4444.jpg      0   \n",
      "2845  104860  img/image_4860.png      0   \n",
      "\n",
      "                                                   text  \n",
      "285   this is bill bill has no arms knock knock who ...  \n",
      "2977                 president dr evil trump a deepfake  \n",
      "1239  2019 jim carrey looks like that cool aunt you ...  \n",
      "665   you cant spell feminism opening mon tue thus f...  \n",
      "2719  when ur wife forces u to delete 30 000 emails ...  \n",
      "...                                                 ...  \n",
      "1982  how u feel when u drop a dank meme on the time...  \n",
      "1465  i don t care what you think of me fb com minio...  \n",
      "2501                                who wore it better   \n",
      "2588  when a cat closes its eyes around you it means...  \n",
      "2845  4g 64 00 06 0000 maxandharveyfangirl1 what i t...  \n",
      "\n",
      "[424 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "non_hateful_df = output[output['label'] == 0]\n",
    "# print(non_hateful_df)\n",
    "# the training dataset from hateful memes contains 5481 0s and 3019 1s, so I'll pick 424 0s and all 276 1s\n",
    "# train = pd.read_json(os.path.join(home, \"annotations/train.jsonl\"), lines=True)\n",
    "# print(train['label'].value_counts())\n",
    "non_hateful_selected = non_hateful_df.sample(n = 424, random_state = 1)\n",
    "# print(non_hateful_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b967a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                 img  label  \\\n",
      "16    100027   img/image_27.jpeg      1   \n",
      "59    100089    img/image_89.jpg      1   \n",
      "70    100105   img/image_105.png      1   \n",
      "100   100153   img/image_153.png      1   \n",
      "102   100158   img/image_158.jpg      1   \n",
      "...      ...                 ...    ...   \n",
      "1982  103425  img/image_3425.jpg      0   \n",
      "1465  102533  img/image_2533.jpg      0   \n",
      "2501  104283  img/image_4283.jpg      0   \n",
      "2588  104444  img/image_4444.jpg      0   \n",
      "2845  104860  img/image_4860.png      0   \n",
      "\n",
      "                                                   text  \n",
      "16    i wonder why who s that they call him hawkeye ...  \n",
      "59         women get over here this instant hmm not bad  \n",
      "70    to be continued baby godfather challange gone ...  \n",
      "100   best of barney i only have one rule never scre...  \n",
      "102   mr mime the barrier pokemon known to make wall...  \n",
      "...                                                 ...  \n",
      "1982  how u feel when u drop a dank meme on the time...  \n",
      "1465  i don t care what you think of me fb com minio...  \n",
      "2501                                who wore it better   \n",
      "2588  when a cat closes its eyes around you it means...  \n",
      "2845  4g 64 00 06 0000 maxandharveyfangirl1 what i t...  \n",
      "\n",
      "[700 rows x 4 columns]\n",
      "         id                 img  label  \\\n",
      "0    103383  img/image_3383.jpg      1   \n",
      "1    106691  img/image_6691.png      1   \n",
      "2    101815  img/image_1815.jpg      0   \n",
      "3    103318  img/image_3318.jpg      0   \n",
      "4    103582  img/image_3582.jpg      0   \n",
      "..      ...                 ...    ...   \n",
      "695  103184  img/image_3184.png      0   \n",
      "696  106039  img/image_6039.jpg      0   \n",
      "697  101676  img/image_1676.jpg      1   \n",
      "698  101374  img/image_1374.jpg      0   \n",
      "699  102695  img/image_2695.jpg      1   \n",
      "\n",
      "                                                  text  \n",
      "0    supreme leader kim jong un targets america for...  \n",
      "1    michelle obama quote white folks are what s wr...  \n",
      "2       merlin s beard cho cho sorry i had a flashback  \n",
      "3    putin must be really loved voted by 100 of rus...  \n",
      "4    this guy can t sing and won t stop dancing hav...  \n",
      "..                                                 ...  \n",
      "695  when you re finished and shestill wants to go ...  \n",
      "696  soest you ll never walk alone this is bill liv...  \n",
      "697  hi sansa how are you now let s make this awkwa...  \n",
      "698                      okay i m not going down there  \n",
      "699  throws her daughter when your daughter s boyfr...  \n",
      "\n",
      "[700 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# concat dfs\n",
    "result = pd.concat([hateful_df, non_hateful_selected])\n",
    "print(result)\n",
    "results = result.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc168b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data to a jsonl file! \n",
    "data = results.to_json(orient='records', lines=True)\n",
    "with open(os.path.join(home, \"annotations/memotion_1k.jsonl\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52f3fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all those images... \n",
    "flist = list(results['img'].str.split('/').str.get(1))\n",
    "# print(flist)\n",
    "# copy these files into another folder: memotion_dataset_7k/images_selected/\n",
    "import zipfile\n",
    "import os\n",
    "os.chdir(os.path.join(home, 'memotion_dataset_7k/images_selected/'))\n",
    "with zipfile.ZipFile('memotion_selected.zip', 'w') as zipMe:        \n",
    "    for file in flist:\n",
    "        zipMe.write(file, compress_type=zipfile.ZIP_DEFLATED)\n",
    "!mv memotion_selected.zip ../images_1k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b61ada70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the file in folder and remove the zip file in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4de82e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all those features! important\n",
    "# os.chdir(os.path.join(home, \"features_memo_4k\"))\n",
    "import shutil\n",
    "flist1 = list(results['img'].str.split('/').str.get(1).str.split('.').str.get(0))\n",
    "# print(flist1)\n",
    "source = os.path.join(home, \"features_memo_4k\")\n",
    "dest = os.path.join(home, \"features_memo_1k\")\n",
    "for f in flist1: \n",
    "    fname = f + '.npy'\n",
    "    shutil.copyfile(os.path.join(source, fname), os.path.join(dest, fname))\n",
    "    fname = f + '_info.npy'\n",
    "    shutil.copyfile(os.path.join(source, fname), os.path.join(dest, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all done! all 700 image features and the jsonl files are ready"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
